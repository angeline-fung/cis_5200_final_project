{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"eQNBxWgt3Rj8"},"outputs":[{"name":"stdout","output_type":"stream","text":["[cuml.accel] Failed to check cudaDevAttrConcurrentManagedAccess with error 35\n","Requirement already satisfied: category_encoders in /usr/local/lib/python3.12/dist-packages (2.9.0)\n","Requirement already satisfied: numpy\u003e=1.14.0 in /usr/local/lib/python3.12/dist-packages (from category_encoders) (2.0.2)\n","Requirement already satisfied: pandas\u003e=1.0.5 in /usr/local/lib/python3.12/dist-packages (from category_encoders) (2.2.2)\n","Requirement already satisfied: patsy\u003e=0.5.1 in /usr/local/lib/python3.12/dist-packages (from category_encoders) (1.0.2)\n","Requirement already satisfied: scikit-learn\u003e=1.6.0 in /usr/local/lib/python3.12/dist-packages (from category_encoders) (1.6.1)\n","Requirement already satisfied: scipy\u003e=1.0.0 in /usr/local/lib/python3.12/dist-packages (from category_encoders) (1.16.3)\n","Requirement already satisfied: statsmodels\u003e=0.9.0 in /usr/local/lib/python3.12/dist-packages (from category_encoders) (0.14.5)\n","Requirement already satisfied: python-dateutil\u003e=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas\u003e=1.0.5-\u003ecategory_encoders) (2.9.0.post0)\n","Requirement already satisfied: pytz\u003e=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas\u003e=1.0.5-\u003ecategory_encoders) (2025.2)\n","Requirement already satisfied: tzdata\u003e=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas\u003e=1.0.5-\u003ecategory_encoders) (2025.2)\n","Requirement already satisfied: joblib\u003e=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn\u003e=1.6.0-\u003ecategory_encoders) (1.5.2)\n","Requirement already satisfied: threadpoolctl\u003e=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn\u003e=1.6.0-\u003ecategory_encoders) (3.6.0)\n","Requirement already satisfied: packaging\u003e=21.3 in /usr/local/lib/python3.12/dist-packages (from statsmodels\u003e=0.9.0-\u003ecategory_encoders) (25.0)\n","Requirement already satisfied: six\u003e=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil\u003e=2.8.2-\u003epandas\u003e=1.0.5-\u003ecategory_encoders) (1.17.0)\n"]}],"source":["# need this package for the pipeline script\n","!pip install category_encoders"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17753,"status":"ok","timestamp":1765061792140,"user":{"displayName":"Man-Ching Fung","userId":"01597576862106041674"},"user_tz":300},"id":"Po1VpFaq1-hS","outputId":"c531ac67-e13b-4786-fdec-d846b203bc10"},"outputs":[{"name":"stdout","output_type":"stream","text":["[cuml.accel] Failed to check cudaDevAttrConcurrentManagedAccess with error 35\n","[cuml.accel] Could not enable managed memory on this platform.\n","[cuml.accel] Accelerator installed.\n"]}],"source":["import cuml\n","from cuml.ensemble import RandomForestRegressor as cuRF_Regressor\n","from cuml.ensemble import RandomForestClassifier as cuRF_Classifier\n","# Install with desired log level before other imports\n","cuml.accel.install(log_level=\"debug\")"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":106,"status":"ok","timestamp":1765053074601,"user":{"displayName":"Man-Ching Fung","userId":"01597576862106041674"},"user_tz":300},"id":"4Vg8QcBMos0L","outputId":"b436edce-253b-4fb7-c41f-f2eef1281a86"},"outputs":[{"name":"stdout","output_type":"stream","text":["ls: cannot access '/content/drive/My Drive/CIS 5200 Final Project/code': No such file or directory\n"]}],"source":[]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":381},"executionInfo":{"elapsed":121624,"status":"error","timestamp":1765062101163,"user":{"displayName":"Man-Ching Fung","userId":"01597576862106041674"},"user_tz":300},"id":"7hqksbIiylB6","outputId":"d7d87dcf-7570-4182-cff2-845924a1c812"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive not mounted, so nothing to flush and unmount.\n"]},{"ename":"ValueError","evalue":"mount failed","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-1868126924.py\u001b[0m in \u001b[0;36m\u003ccell line: 0\u003e\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# force remount\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush_and_unmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---\u003e 15\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---\u003e 97\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m     98\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    270\u001b[0m             \u001b[0;34m'https://research.google.com/colaboratory/faq.html#drive-timeout'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m         )\n\u001b[0;32m--\u003e 272\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mount failed'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mextra_reason\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m       \u001b[0;31m# Terminate the DriveFS binary before killing bash.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: mount failed"]}],"source":["from sklearn.model_selection import RandomizedSearchCV\n","from sklearn.pipeline import Pipeline\n","\n","# from sklearn.ensemble import RandomForestClassifier\n","# from sklearn.ensemble import RandomForestRegressor\n","import pandas as pd\n","import numpy as np\n","import os\n","import sys\n","import os\n","from google.colab import drive\n","\n","# force remount\n","drive.flush_and_unmount()\n","drive.mount('/content/drive', force_remount=True)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":28,"status":"aborted","timestamp":1765062101186,"user":{"displayName":"Man-Ching Fung","userId":"01597576862106041674"},"user_tz":300},"id":"kWvBgRw4XOrv"},"outputs":[],"source":["!ls \"/content/drive/My Drive/CIS 5200 Final Project/code\"\n"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1765053108809,"user":{"displayName":"Man-Ching Fung","userId":"01597576862106041674"},"user_tz":300},"id":"Ds-jpLnerxgY","outputId":"72a82f21-c7d6-4687-b395-653f34f2c19e"},"outputs":[{"data":{"text/plain":["['/content',\n"," '/env/python',\n"," '/usr/lib/python312.zip',\n"," '/usr/lib/python3.12',\n"," '/usr/lib/python3.12/lib-dynload',\n"," '',\n"," '/usr/local/lib/python3.12/dist-packages',\n"," '/usr/lib/python3/dist-packages',\n"," '/usr/local/lib/python3.12/dist-packages/IPython/extensions',\n"," '/root/.ipython']"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["sys.path"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":41,"status":"ok","timestamp":1765053217209,"user":{"displayName":"Man-Ching Fung","userId":"01597576862106041674"},"user_tz":300},"id":"fYnfYXXJpJP-","outputId":"99e5a2a3-4bc7-420d-85cf-8f7ea1a6649a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Successfully loaded pipeline!\n"]}],"source":["import sys\n","\n","# 2. Add your project path to Python's system path\n","# This tells Python: \"Look in this folder when I try to import things\"\n","project_path = '/content/drive/My Drive/CIS 5200 Final Project/code'\n","\n","if project_path not in sys.path:\n","    sys.path.append(project_path)\n","\n","# can use importlib to safely reload if you change the script\n","import rf_classification\n","import importlib\n","importlib.reload(rf_classification)\n","from rf_classification import train_classifier, InferencePipeline, get_classifier_pipeline\n","\n","\n","print(\"Successfully loaded pipeline!\")\n","\n"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":446,"status":"ok","timestamp":1765051189775,"user":{"displayName":"Man-Ching Fung","userId":"01597576862106041674"},"user_tz":300},"id":"4fJTn9zW54UR"},"outputs":[],"source":["# -*- coding: utf-8 -*-\n","\"\"\"rf_pipeline.ipynb\n","\n","Automatically generated by Colab.\n","\n","Original file is located at\n","    https://colab.research.google.com/drive/1d8BpmDV7Ky474h1FRWA4plu0TTjODC9O\n","\"\"\"\n","\n","import pandas as pd\n","import numpy as np\n","import os\n","import joblib\n","import gc\n","import json\n","import time\n","from datetime import datetime\n","\n","from sklearn.pipeline import Pipeline\n","from sklearn.base import BaseEstimator, TransformerMixin\n","from sklearn.model_selection import train_test_split\n","from sklearn.compose import ColumnTransformer\n","from sklearn.preprocessing import OrdinalEncoder\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import (\n","    accuracy_score, f1_score, precision_score, recall_score,\n","    confusion_matrix, roc_auc_score, log_loss, average_precision_score\n",")\n","\n","# --- Configuration ---\n","CLASS_TARGET = 'DEP_DEL15'\n","LEAKAGE_COLS = ['CARRIER_DELAY', 'WEATHER_DELAY', 'NAS_DELAY',\n","                'SECURITY_DELAY', 'LATE_AIRCRAFT_DELAY']\n","\n","# Define Categoricals (Same as before)\n","CATEGORICAL_COLS = [\n","    # Core IDs\n","    'CARRIER_NAME',\n","    'DEPARTING_AIRPORT',\n","    'PREVIOUS_AIRPORT',\n","    'DESTINATION_AIRPORT',\n","    # Engineered Routes\n","    'ROUTE_NAME',      # Origin -\u003e Dest\n","    'INCOMING_ROUTE',  # Prev -\u003e Origin\n","    'CARRIER_AIRPORT', # Hub Effect\n","    # Time\n","    'DEP_TIME_BLK',\n","    'MONTH',\n","    'DAY_OF_WEEK',\n","    'SEASON',\n","    # Groups\n","    'DISTANCE_GROUP',\n","    'SEGMENT_NUMBER',\n","    # Weather Flags / binary flags\n","    'IS_HEAVY_RAIN', 'IS_SNOWY',\n","    'IS_FREEZING', 'IS_EXTREME_HEAT',\n","    'AWND_missing', 'TMIN_missing', 'TMAX_missing',\n","]\n","# Add WT flags\n","CATEGORICAL_COLS.extend([f'WT{str(i).zfill(2)}' for i in range(1, 12)])\n","\n","\n","# --- Transformers ---\n","class ColumnDropper(BaseEstimator, TransformerMixin):\n","    \"\"\"Drop known leakage columns.\"\"\"\n","    def __init__(self, columns_to_drop):\n","        self.columns_to_drop = columns_to_drop\n","\n","    def fit(self, X, y=None):\n","        return self\n","\n","    def transform(self, X):\n","        return X.drop(\n","            columns=[c for c in self.columns_to_drop if c in X.columns],\n","            errors=\"ignore\"\n","        )\n","\n","\n","def get_classifier_pipeline():\n","    \"\"\"\n","    Returns a sklearn Pipeline that:\n","      1. Drops leakage columns\n","      2. Ordinal-encodes categorical columns\n","      3. Passes all remaining columns through as numeric features\n","    \"\"\"\n","    preprocessor = ColumnTransformer(\n","        transformers=[\n","            (\n","                \"cat\",\n","                OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1),\n","                CATEGORICAL_COLS\n","            )\n","        ],\n","        remainder=\"passthrough\"  # keep non-categorical columns as-is\n","    )\n","\n","    pipeline = Pipeline(steps=[\n","        (\"dropper\", ColumnDropper(LEAKAGE_COLS)),\n","        (\"preprocessor\", preprocessor),\n","    ])\n","\n","    return pipeline\n","\n","\n","class InferencePipeline:\n","    \"\"\"\n","    Simple wrapper to keep preprocessor + model together\n","    and expose predict / predict_proba.\n","    \"\"\"\n","    def __init__(self, preprocessor, model):\n","        self.preprocessor = preprocessor\n","        self.model = model\n","\n","    def predict(self, X):\n","        X_trans = self.preprocessor.transform(X)\n","        return self.model.predict(X_trans)\n","\n","    def predict_proba(self, X):\n","        X_trans = self.preprocessor.transform(X)\n","        return self.model.predict_proba(X_trans)\n","\n","# best_model_params = {'n_estimators': 200, 'n_bins': 128, 'min_samples_split': 5, 'max_features': 'log2', 'max_depth': 15}\n","\n","\n","# --- Training Function ---\n","def train_classifier(\n","    X_train_path,\n","    y_train_path,\n","    X_test_path,\n","    y_test_path,\n","    description=\"RF_Classifier\",\n","    checkpoint_dir=None,\n","    **model_params\n","):\n","    \"\"\"\n","    Train a RandomForestClassifier with the same structure as your old LGBM pipeline.\n","    - Loads CSVs\n","    - Builds preprocessing pipeline\n","    - Trains RF with stratified validation split\n","    - Evaluates on test set\n","    - Saves InferencePipeline + metrics JSON (if checkpoint_dir is provided)\n","    \"\"\"\n","\n","    print(f\"\\n--- Starting Classifier Training: {description} ---\")\n","\n","    # 1. Load Data\n","    print(\"  Loading Training Data...\")\n","    X_train = pd.read_csv(X_train_path)\n","    y_train = pd.read_csv(y_train_path)[CLASS_TARGET].squeeze()\n","\n","    # 2. Stratified Split for Train and Validation Sets\n","    print(\"  Creating Stratified Validation Split (15%)...\")\n","    X_tr, X_val, y_tr, y_val = train_test_split(\n","        X_train,\n","        y_train,\n","        test_size=0.15,\n","        random_state=42,\n","        stratify=y_train,\n","    )\n","    del X_train, y_train\n","    gc.collect()\n","\n","    # 3. Build Pipeline (drop leakage + ordinal encoding)\n","    pipeline = get_classifier_pipeline()\n","\n","    # 4. Build Random Forest model\n","    rf_default_params = {\n","        \"n_estimators\": 200,\n","        \"max_depth\": 15,\n","        \"max_features\": \"log2\",\n","        \"min_samples_split\": 5,\n","        \"min_samples_leaf\": 5,\n","        \"n_jobs\": -1,\n","        \"class_weight\": \"balanced\",\n","        \"random_state\": 42,\n","    }\n","    rf_default_params.update(model_params)\n","    model = RandomForestClassifier(**rf_default_params)\n","\n","    # 5. Preprocess \u0026 Fit\n","    print(\"  Preprocessing \u0026 Fitting RandomForest...\")\n","    start = time.time()\n","    X_tr_trans = pipeline.fit_transform(X_tr, y_tr)\n","    X_val_trans = pipeline.transform(X_val)\n","\n","    model.fit(X_tr_trans, y_tr)\n","    train_time = time.time() - start\n","    print(f\"  Training finished in {train_time:.1f}s\")\n","\n","    del X_tr, X_val, X_tr_trans, X_val_trans, y_tr, y_val\n","    gc.collect()\n","\n","    # 6. Evaluation on Test Set\n","    print(\"  Evaluating on Test Set...\")\n","    X_test = pd.read_csv(X_test_path)\n","    y_test = pd.read_csv(y_test_path)[CLASS_TARGET].squeeze()\n","\n","    X_test_trans = pipeline.transform(X_test)\n","    y_pred = model.predict(X_test_trans)\n","    y_prob = model.predict_proba(X_test_trans)[:, 1]\n","\n","    # 7. Report Metrics\n","    results = {\n","        \"description\": description,\n","        \"accuracy\": accuracy_score(y_test, y_pred),\n","        \"auc\": roc_auc_score(y_test, y_prob),\n","        \"average_precision/auprc\": average_precision_score(y_test, y_prob),\n","        \"log_loss\": log_loss(y_test, y_prob),\n","        \"f1\": f1_score(y_test, y_pred),\n","        \"precision\": precision_score(y_test, y_pred),\n","        \"recall\": recall_score(y_test, y_pred),\n","        \"confusion_matrix\": confusion_matrix(y_test, y_pred).tolist(),\n","        \"training_time\": train_time,\n","        \"parameters\": model.get_params(),\n","    }\n","\n","    print(f\"  AUC: {results['auc']:.4f}, LogLoss: {results['log_loss']:.4f}\")\n","    print(f\"  Precision: {results['precision']:.4f}, Recall: {results['recall']:.4f}\")\n","\n","    # 8. Save Metrics and Pipeline\n","    if checkpoint_dir:\n","        os.makedirs(checkpoint_dir, exist_ok=True)\n","        safe_desc = \"\".join([c if c.isalnum() else \"_\" for c in description])\n","        ts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n","\n","        # Save full inference pipeline (preprocessing + RF model)\n","        path = os.path.join(checkpoint_dir, f\"RF_CLS_{safe_desc}_{ts}.joblib\")\n","        joblib.dump(InferencePipeline(pipeline, model), path)\n","        results[\"checkpoint_path\"] = path\n","\n","        # Save metrics\n","        metrics_path = path.replace(\".joblib\", \"_metrics.json\")\n","        with open(metrics_path, \"w\") as f:\n","            json.dump(results, f, indent=4)\n","\n","    return results"]},{"cell_type":"markdown","metadata":{"id":"9hZ_x-JNaKpb"},"source":["# Load and Prep Data (as necessary)"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1765053226757,"user":{"displayName":"Man-Ching Fung","userId":"01597576862106041674"},"user_tz":300},"id":"IzWAibHY-nz5"},"outputs":[],"source":["# i=1\n","# mod = f'{i}'\n","mod = \"added_delay_20251202_034422\"\n","\n","DATA_FILE_PATH = \"/content/drive/My Drive/CIS 5200 Final Project/train_test_datasets/\"\n","checkpoint_dir = \"/content/drive/My Drive/CIS 5200 Final Project/models/random_forests/\"\n","\n","# 1. Load the dataset and drop rows with missing values\n","X_train_path = DATA_FILE_PATH + f'X_train_{mod}.csv'\n","y_train_path = DATA_FILE_PATH + f'y_train_{mod}.csv'\n","\n","X_test_path = DATA_FILE_PATH + f'X_test_{mod}.csv'\n","y_test_path = DATA_FILE_PATH + f'y_test_{mod}.csv'\n","\n","# Regression\n","REGR_TARGET = 'DEP_ADDED_DELAY'\n","\n","# Classification\n","CLASS_TARGET='DEP_DEL15'"]},{"cell_type":"markdown","metadata":{"id":"9Kbp_UYXPtHz"},"source":["## HyperParameter Randomized Search, cuML random forests"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"Wjlt4e--Psv4"},"outputs":[],"source":["target = 'DEP_ADDED_DELAY'\n","# 1. Load a SUBSET of data for tuning (e.g., 100k rows)\n","# Tuning on the full 1.2M dataset is overkill and slow for CV\n","X_tune = pd.read_csv(X_train_path, nrows=200000)\n","y_tune = pd.read_csv(y_train_path, nrows=200000)[target]\n","\n","# 2. Get your existing preprocessing pipeline (without the model)\n","# note: flight_delay_pipeline.py returns a pipeline ending in 'preprocessor'\n","prep_pipeline = get_preprocessing_pipeline()\n","\n","# 3. Create the Full Pipeline (Prep + GPU Model)\n","# We add the model as the final step\n","full_pipeline = Pipeline(steps=[\n","    ('prep', prep_pipeline),\n","    ('model', cuRF_Regressor(verbose=0)) # Turn off model verbosity to keep output clean\n","])\n","\n","# 4. Define the Parameter Grid\n","# Note the 'model__' prefix which tells sklearn to apply these to the 'model' step\n","param_dist = {\n","    'model__n_estimators': [100, 150, 200, 250, 300],     # More trees = better but slower\n","    'model__max_depth': [10, 15, 20, 25, 30],       # Depth controls overfitting\n","    'model__max_features': ['sqrt', 'log2'],    # Features per split\n","    'model__n_bins': [32, 64, 128, 256],             # Lower bins = Faster, less GPU RAM\n","    'model__min_samples_split': [2, 5, 10],\n","}\n","\n","# 5. Setup RandomizedSearchCV\n","search = RandomizedSearchCV(\n","    estimator=full_pipeline,\n","    param_distributions=param_dist,\n","    n_iter=20,          # Try 20 random combinations\n","    cv=3,               # 3-Fold CV is enough for tuning\n","    scoring='neg_mean_absolute_error',\n","    n_jobs=1,           # CRITICAL: Keep this at 1 to avoid GPU OOM\n","    verbose=3,          # See progress\n","    random_state=42\n",")\n","\n","# 6. Run the search\n","print(\"Starting Hyperparameter Sweep...\")\n","search.fit(X_tune, y_tune)\n","\n","print(f\"Best Params: {search.best_params_}\")\n","# The \"best_score_\" will now be negative MAE (e.g., -15.4)\n","print(f\"Best MAE (Validation): {search.best_score_}\")\n","\n","# 7. (Optional) Save the best params to use in your main script\n","best_model_params = {k.replace('model__', ''): v for k, v in search.best_params_.items()}\n","print(\"Params ready for train_model:\", best_model_params)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":176},"executionInfo":{"elapsed":31,"status":"error","timestamp":1764861169231,"user":{"displayName":"Man-Ching Fung","userId":"01597576862106041674"},"user_tz":300},"id":"fu-I2FmpUlhl","outputId":"c7cd9550-f25d-44dd-8f25-bf6853ccd37a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Best Parameters for RF with Randomized Grid Search\n"]},{"ename":"NameError","evalue":"name 'pprint' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-2094566002.py\u001b[0m in \u001b[0;36m\u003ccell line: 0\u003e\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Best Parameters for RF with Randomized Grid Search'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----\u003e 2\u001b[0;31m \u001b[0mpprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_model_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'pprint' is not defined"]}],"source":["\n","print('Best Parameters for RF with Randomized Grid Search')\n","pprint(best_model_params)"]},{"cell_type":"markdown","metadata":{"id":"fjaHlDADaL-K"},"source":["# Setup the Random Forest\n","Some important hyperparameters for a Random Forest:\n","1. n_estimators: the # of decision trees to ensemble (default=100)\n","\n","2. max_features: the max # of features a decision tree will be allowed to consider (default = sqrt(N_features))\n","\n","3. max_depth: max depth a tree will be allowed to reach (default = inf)\n","\n","4. max_leaf_nodes: max number of leaf nodes a tree can hold (default = inf)\n","\n","5. max_sample: how many samples from the training set that a decision tree can see (default = entire training set)\n","\n","6. min_samples_split: The threshold for which a node can be split (default = 2)\n","\n","More hyperparams [here](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"62-c02mcvogk"},"outputs":[],"source":["from pprint import pprint"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3LlYoUF9aODj"},"outputs":[],"source":["# define hyperparameters for RandomForestRegressor\n","# n_estimators=5000\n","# max_features=\"sqrt\"\n","# max_depth=16 # cuML default is 16, sklearn default is inf\n","# max_leaves=-1 #inf\n","# max_samples=1.0 # all samples\n","# min_samples_split=2\n","# criterion=\"squared_error\" # \"absolute error\" # is an option, but much slower per the sklearn docs\n","# verbose=2\n","# n_binsint (default = 128) # Maximum number of bins used by the split algorithm per feature.\n","# For large problems, particularly those with highly-skewed input data, increasing the number of bins may improve accuracy.\n","# https://docs.rapids.ai/api/cuml/stable/api/#output-data-type-configuration, default is 'input', so for pandas inputs == numpy array outputs\n","best_model_params = {'n_estimators': 200, 'n_bins': 128, 'min_samples_split': 5, 'max_features': 'log2', 'max_depth': 15}\n","\n","\n","## Regression\n","# params = {'n_estimators': 200, 'max_features': 'sqrt', 'max_depth': 30,\n","#           'max_leaves': -1, 'max_samples': 1.0, 'min_samples_split': 2,\n","#           'n_bins': 256, 'criterion': 'squared_error', 'verbose': 2}\n","\n","# params.update(best_model_params)\n","# pprint(params)\n","# model=cuRF_Regressor(**params)\n","\n","## Classification\n","params = {'n_estimators': 200, 'max_features': 'sqrt', 'max_depth': 30,\n","          'max_leaves': -1, 'max_samples': 1.0, 'min_samples_split': 2,\n","          'n_bins': 256, 'criterion': 'entropy', 'verbose': 2}\n","\n","params.update(best_model_params)\n","model=cuRF_Classifier(**params)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1764864877158,"user":{"displayName":"Man-Ching Fung","userId":"01597576862106041674"},"user_tz":300},"id":"RkQqRmB1YACD","outputId":"b22d90bd-d216-490c-fa5a-b452713aef1a"},"outputs":[{"name":"stdout","output_type":"stream","text":["('/content/drive/My Drive/CIS 5200 Final '\n"," 'Project/train_test_datasets/X_train_added_delay_20251202_034422.csv')\n","('/content/drive/My Drive/CIS 5200 Final '\n"," 'Project/train_test_datasets/X_test_added_delay_20251202_034422.csv')\n","('/content/drive/My Drive/CIS 5200 Final '\n"," 'Project/train_test_datasets/y_train_added_delay_20251202_034422.csv')\n","('/content/drive/My Drive/CIS 5200 Final '\n"," 'Project/train_test_datasets/y_test_added_delay_20251202_034422.csv')\n"]}],"source":["pprint(X_train_path)\n","pprint(X_test_path)\n","pprint(y_train_path)\n","pprint(y_test_path)"]},{"cell_type":"markdown","metadata":{"id":"ixJwvXAm-kuB"},"source":["# Train Model on Datasets"]},{"cell_type":"markdown","metadata":{"id":"9rd4zBvrYuU7"},"source":["## Full Dataset"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2329269,"status":"ok","timestamp":1765055579652,"user":{"displayName":"Man-Ching Fung","userId":"01597576862106041674"},"user_tz":300},"id":"EIqCcM1M-ztn","outputId":"113937eb-efa2-465f-cd56-05528609f83d"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","--- Starting Classifier Training: cuML RFClass Dataset added_delay_20251202_034422 ---\n","  Loading Training Data...\n","  Creating Stratified Validation Split (15%)...\n","  Preprocessing \u0026 Fitting RandomForest...\n","[cuml.accel] `RandomForestClassifier.fit` falling back to CPU: `class_weight` is not supported\n","[cuml.accel] `RandomForestClassifier.fit` ran on CPU\n","  Training finished in 2179.7s\n","  Evaluating on Test Set...\n","[cuml.accel] `RandomForestClassifier.predict` ran on CPU\n","[cuml.accel] `RandomForestClassifier.predict_proba` ran on CPU\n","  AUC: 0.8407, LogLoss: 0.5277\n","  Precision: 0.3971, Recall: 0.7724\n"]}],"source":["# i=1\n","\n","model_type = 'classification'\n","description = f\"cuML RFClass Dataset {mod}\"\n","\n","# model_type = 'regression'\n","# description = f\"cuML RFReg Dataset {mod}\"\n","\n","# DATA_FILE_PATH = \"/content/drive/My Drive/CIS 5200 Final Project/train_test_datasets/no_encodings/\"\n","# checkpoint_dir = \"/content/drive/My Drive/CIS 5200 Final Project/models/random forests/\"\n","\n","# # 1. Load the dataset and drop rows with missing values\n","# X_train_path = DATA_FILE_PATH + f'X_train_{mod}_no_encoding.csv'\n","# y_train_path = DATA_FILE_PATH + f'y_train_{mod}_no_encoding.csv'\n","\n","# X_test_path = DATA_FILE_PATH + f'X_test_{mod}_no_encoding.csv'\n","# y_test_path = DATA_FILE_PATH + f'y_test_{mod}_no_encoding.csv'\n","\n","\n","\n","# --- Training Function ---\n","# def train_classifier(\n","#     X_train_path,\n","#     y_train_path,\n","#     X_test_path,\n","#     y_test_path,\n","#     description=\"RF_Classifier\",\n","#     checkpoint_dir=None,\n","#     **model_params\n","# ):\n","\n","results = train_classifier(X_train_path=X_train_path, y_train_path=y_train_path,\n","                      X_test_path=X_test_path, y_test_path=y_test_path, description=description,\n","                      checkpoint_dir=checkpoint_dir)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cY-gXU3bSBIo"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"m52MqnsnXhhM"},"source":["# Run a Dummy Inference Example"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1764454207865,"user":{"displayName":"Man-Ching Fung","userId":"01597576862106041674"},"user_tz":360},"id":"_RGHrBCFqnkS","outputId":"73165ae1-637b-48e7-c9a6-f15b60dfb633"},"outputs":[{"name":"stdout","output_type":"stream","text":["{'description': 'cuML RFClass Dataset full', 'training_time_sec': 192.36317372322083, 'timestamp': '2025-11-29 22:07:08', 'pipeline': \u003cflight_delay_pipeline.InferencePipeline object at 0x7b0c9aa0b8f0\u003e, 'accuracy': 0.8314834271262256, 'f1': 0.0637138600147684, 'precision': 0.7586888657648283, 'recall': 0.03325321426453887, 'confusion_matrix': array([[1050020,    2319],\n","       [ 211966,    7291]]), 'checkpoint_path': '/content/drive/My Drive/CIS 5200 Final Project/models/random forests/cuML_RFClass_Dataset_full_20251129_220708.joblib'}\n"]}],"source":["print(results)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":42,"status":"ok","timestamp":1764825120897,"user":{"displayName":"Man-Ching Fung","userId":"01597576862106041674"},"user_tz":300},"id":"0XcOAcX4qadA","outputId":"b9cc6272-5f40-4d5f-d1e0-0f76cb491d0e"},"outputs":[{"data":{"text/plain":["dict_keys(['description', 'training_time_sec', 'timestamp', 'pipeline', 'accuracy', 'f1', 'precision', 'recall', 'confusion_matrix', 'checkpoint_path'])"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["results.keys()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":329,"status":"ok","timestamp":1764825122322,"user":{"displayName":"Man-Ching Fung","userId":"01597576862106041674"},"user_tz":300},"id":"7RljGsl-rgG_","outputId":"5f427790-9a26-476b-a520-434370f0136e"},"outputs":[{"data":{"text/plain":["{'description': 'cuML RFClass Dataset added_delay_20251202_034422',\n"," 'training_time_sec': 168.03658390045166,\n"," 'timestamp': '2025-12-04 05:11:46',\n"," 'pipeline': \u003cflight_delay_pipeline.InferencePipeline at 0x783096220680\u003e,\n"," 'accuracy': 0.8293420237245163,\n"," 'f1': 0.02556779912169626,\n"," 'precision': 0.8264150943396227,\n"," 'recall': 0.012984762174069698,\n"," 'confusion_matrix': array([[1051741,     598],\n","        [ 216410,    2847]])}"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["from joblib import load\n","\n","rf_performance = load(results[\"checkpoint_path\"])\n","\n","rf_performance"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6_7TjKC0XX_o"},"outputs":[],"source":["X_tune = pd.read_csv(X_train_path, nrows=200000)\n","y_tune = pd.read_csv(y_train_path, nrows=200000)[CLASS_TARGET]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":38,"status":"ok","timestamp":1764367490737,"user":{"displayName":"Roy","userId":"18018327479916660485"},"user_tz":300},"id":"XHg_1U4ZXfnD","outputId":"2e222176-4f81-41f2-f05f-823329a31b76"},"outputs":[{"name":"stdout","output_type":"stream","text":["   MONTH  DAY_OF_WEEK DEP_TIME_BLK  DISTANCE_GROUP  SEGMENT_NUMBER  \\\n","0      5            7    1000-1059               4               1   \n","\n","   CONCURRENT_FLIGHTS  NUMBER_OF_SEATS            CARRIER_NAME  \\\n","0                   6              140  American Airlines Inc.   \n","\n","   AIRPORT_FLIGHTS_MONTH  AIRLINE_FLIGHTS_MONTH  ...  WT05  WT06  WT07  WT08  \\\n","0                   2588                  78894  ...   0.0   0.0   0.0   0.0   \n","\n","   WT09  WT10 WT11 AWND_missing  TMIN_missing  TMAX_missing  \n","0   0.0   0.0  0.0        False         False         False  \n","\n","[1 rows x 38 columns]\n","0    0\n","Name: DEP_DEL15, dtype: int64\n"]}],"source":["pprint(X_tune[:1])\n","pprint(y_tune[:1])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e19za2flWY31"},"outputs":[],"source":["import joblib\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","# # 1. Define the wrapper class (or import it from your pipeline script)\n","# class InferencePipeline:\n","#     def __init__(self, preprocessor, model):\n","#         self.preprocessor = preprocessor\n","#         self.model = model\n","#     def predict(self, X):\n","#         X_trans = self.preprocessor.transform(X).astype(np.float32)\n","#         return self.model.predict(X_trans)\n","\n","# 2. Load the checkpoint\n","checkpoint_dir = '/content/drive/My Drive/CIS 5200 Final Project/models/random_forests/'\n","chk_path = \"/content/drive/My Drive/CIS 5200 Final Project/models/random_forests/cuML_RFClass_Dataset_added_delay_20251202_034422_20251204_051146.joblib\"\n","# chk_path = checkpoint_dir + 'cuML_RFClass_Dataset_full_20251128_220339.joblib'\n","checkpoint = joblib.load(chk_path)\n","\n","# 3. Extract your custom pipeline from the results dictionary\n","inference_pipe = checkpoint['pipeline']\n","\n","model = inference_pipe.model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K_YWTb_z2_H0"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":159},"executionInfo":{"elapsed":15,"status":"error","timestamp":1764541208341,"user":{"displayName":"Roy","userId":"18018327479916660485"},"user_tz":300},"id":"0oauMD551MIn","outputId":"149c69d4-9575-4af0-bea6-968ea173f764"},"outputs":[{"ename":"AttributeError","evalue":"'RandomForestClassifier' object has no attribute 'feature_importances_'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-1618517963.py\u001b[0m in \u001b[0;36m\u003ccell line: 0\u003e\u001b[0;34m()\u001b[0m\n\u001b[0;32m----\u003e 1\u001b[0;31m \u001b[0mimportances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_importances_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mstd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_importances_\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtree\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'RandomForestClassifier' object has no attribute 'feature_importances_'"]}],"source":["importances = model.feature_importances_\n","std = np.std([tree.feature_importances_ for tree in model.estimators_], axis=0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pklmZX3U0sb9"},"outputs":[],"source":["\n","# 5. Convert to DataFrame and Predict\n","df_example = X_tune[:1]\n","\n","\n","# Run Inference\n","prediction = inference_pipe.predict(df_example)\n","# Regression\n","# print(f\"Predicted Delay: {prediction[0]:.2f} minutes\")\n","# Clasisfication\n","print(f\"Predicted Class (0 = Ontime, 1 = Delayed \u003e= 15): {prediction[0]}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UgrwYdglXbw2"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20,"status":"ok","timestamp":1764825313125,"user":{"displayName":"Man-Ching Fung","userId":"01597576862106041674"},"user_tz":300},"id":"FcneqdDwyNwy","outputId":"885633b5-c855-439b-bf3d-fca684feef36"},"outputs":[{"name":"stdout","output_type":"stream","text":["{'criterion': 'squared_error',\n"," 'max_depth': 15,\n"," 'max_features': 'log2',\n"," 'max_leaves': -1,\n"," 'max_samples': 1.0,\n"," 'min_samples_split': 5,\n"," 'n_bins': 128,\n"," 'n_estimators': 200,\n"," 'verbose': 2}\n"]}],"source":["# best_model_params = {'n_estimators': 200, 'n_bins': 128, 'min_samples_split': 5, 'max_features': 'log2', 'max_depth': 15}\n","\n","\n","# Regression\n","params = {'n_estimators': 200, 'max_features': 'sqrt', 'max_depth': 30,\n","          'max_leaves': -1, 'max_samples': 1.0, 'min_samples_split': 2,\n","          'n_bins': 256, 'criterion': 'squared_error', 'verbose': 2}\n","\n","params.update(best_model_params)\n","pprint(params)\n","model=cuRF_Regressor(**params)\n","\n","## Classification\n","# params = {'n_estimators': 200, 'max_features': 'sqrt', 'max_depth': 30,\n","#           'max_leaves': -1, 'max_samples': 1.0, 'min_samples_split': 2,\n","#           'n_bins': 256, 'criterion': 'entropy', 'verbose': 2}\n","\n","# params.update(best_model_params)\n","# pprint(params)\n","# model=cuRF_Classifier(**params)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WRZDrp8EzGz9"},"outputs":[],"source":["mask_delay = y_train[\"DEP_ADDED_DELAY\"] \u003e 0\n","\n","X_train_reg = X_train.loc[mask_delay].copy()\n","y_train_reg = y_train.loc[mask_delay].copy()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wTBcuSeLyNtp"},"outputs":[],"source":["\n","\n","results_regressor = train_model(X_train_path=X_train_path, y_train_path=y_train_path,\n","                      X_test_path=X_test_path, y_test_path=y_test_path, model=model,\n","                      checkpoint_dir=checkpoint_dir, description=description,\n","                      model_type=model_type, model_name='rapid_rf')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FQi973tMvxdn"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CKrVaNsjvxbj"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UeNIJfd3vxYr"},"outputs":[],"source":["# import pandas as pd\n","# import numpy as np\n","# import os\n","# import joblib\n","# import gc\n","# import json\n","# import time\n","# from datetime import datetime\n","\n","# from sklearn.pipeline import Pipeline\n","# from sklearn.base import BaseEstimator, TransformerMixin\n","# from sklearn.model_selection import train_test_split\n","# from sklearn.compose import ColumnTransformer\n","# from sklearn.preprocessing import OrdinalEncoder\n","# from sklearn.ensemble import RandomForestRegressor\n","# from sklearn.metrics import (\n","#     root_mean_squared_error, mean_absolute_error, r2_score,\n","#     mean_tweedie_deviance, mean_gamma_deviance, mean_absolute_percentage_error\n","# )\n","\n","# # --- Configuration ---\n","# REGR_TARGET = 'DEP_ADDED_DELAY'\n","# LEAKAGE_COLS = ['CARRIER_DELAY', 'WEATHER_DELAY',\n","#                 'NAS_DELAY', 'SECURITY_DELAY',\n","#                 'LATE_AIRCRAFT_DELAY']\n","\n","# CATEGORICAL_COLS = [\n","#     'CARRIER_NAME', 'DEPARTING_AIRPORT', 'PREVIOUS_AIRPORT', 'DESTINATION_AIRPORT',\n","#     'ROUTE_NAME', 'INCOMING_ROUTE', 'CARRIER_AIRPORT',\n","#     'DEP_TIME_BLK', 'MONTH', 'DAY_OF_WEEK', 'SEASON',\n","#     'DISTANCE_GROUP', 'SEGMENT_NUMBER',\n","#     'IS_HEAVY_RAIN', 'IS_SNOWY', 'IS_FREEZING', 'IS_EXTREME_HEAT',\n","#     'AWND_missing', 'TMIN_missing', 'TMAX_missing',\n","# ]\n","# CATEGORICAL_COLS.extend([f'WT{str(i).zfill(2)}' for i in range(1, 12)])\n","\n","\n","# # --- Transformers ---\n","# class ColumnDropper(BaseEstimator, TransformerMixin):\n","#     def __init__(self, columns_to_drop):\n","#         self.columns_to_drop = columns_to_drop\n","\n","#     def fit(self, X, y=None):\n","#         return self\n","\n","#     def transform(self, X):\n","#         return X.drop(columns=[c for c in self.columns_to_drop if c in X.columns])\n","\n","\n","# def get_regressor_pipeline():\n","#     \"\"\"\n","#     Drop leakage columns, then ordinal-encode categorical features and\n","#     passthrough the rest.\n","#     \"\"\"\n","#     preprocessor = ColumnTransformer(\n","#         transformers=[\n","#             (\n","#                 \"cat\",\n","#                 OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1),\n","#                 CATEGORICAL_COLS,\n","#             ),\n","#         ],\n","#         remainder=\"passthrough\",  # keep non-categorical columns as-is\n","#     )\n","\n","#     pipe = Pipeline(steps=[\n","#         ('dropper', ColumnDropper(LEAKAGE_COLS)),\n","#         ('preprocessor', preprocessor),\n","#     ])\n","#     return pipe\n","\n","\n","# class InferencePipeline:\n","#     \"\"\"\n","#     Wrapper that keeps preprocessor + model together and exposes predict.\n","#     \"\"\"\n","#     def __init__(self, preprocessor, model):\n","#         self.preprocessor = preprocessor\n","#         self.model = model\n","\n","#     def predict(self, X):\n","#         X_trans = self.preprocessor.transform(X)\n","#         return self.model.predict(X_trans)\n","\n","\n","# # --- Training Function ---\n","# def train_regressor(\n","#     X_train_path,\n","#     y_train_path,\n","#     X_test_path,\n","#     y_test_path,\n","#     stopping_rounds=100,  # kept for API compatibility, not used by RF\n","#     description=\"RF_Regressor\",\n","#     pos_only=False,\n","#     extra_metrics=None,\n","#     checkpoint_dir=None,\n","#     **model_params,\n","# ):\n","#     \"\"\"\n","#     Train a RandomForestRegressor with your flight-delay features.\n","\n","#     - Optionally trains only on rows with DEP_ADDED_DELAY \u003e 0 (pos_only=True)\n","#     - Uses a 15% validation split (for monitoring only)\n","#     - Saves an InferencePipeline (preprocessor + RF model) plus metrics JSON\n","#     \"\"\"\n","\n","#     print(f\"\\n--- Starting Regressor Training: {description} ---\")\n","\n","#     # 1. Load Data\n","#     print(\"  Loading Training Data...\")\n","#     X_train = pd.read_csv(X_train_path)\n","#     y_train = pd.read_csv(y_train_path)[REGR_TARGET].squeeze()\n","\n","#     if pos_only:\n","#         print(f\"  Filtering for positive delays... (Original: {len(X_train)})\")\n","#         mask_pos = (y_train \u003e 0)\n","#         X_train = X_train[mask_pos]\n","#         y_train = y_train[mask_pos]\n","#         print(f\"  Training samples remaining: {len(X_train)}\")\n","#     else:\n","#         print(\"  pos_only is False, training on WHOLE training set\")\n","\n","#     # 2. Split\n","#     print(\"  Creating Validation Split (15%)...\")\n","#     X_tr, X_val, y_tr, y_val = train_test_split(\n","#         X_train,\n","#         y_train,\n","#         test_size=0.15,\n","#         random_state=42,\n","#     )\n","#     del X_train, y_train\n","#     gc.collect()\n","\n","#     # 3. Pipeline Setup\n","#     pipeline = get_regressor_pipeline()\n","\n","#     # 4. Build RandomForestRegressor\n","#     rf_params = {\n","#         \"n_estimators\": 300,\n","#         \"max_depth\": None,\n","#         \"max_features\": \"sqrt\",\n","#         \"min_samples_split\": 2,\n","#         \"min_samples_leaf\": 1,\n","#         \"n_jobs\": -1,\n","#         \"random_state\": 42,\n","#     }\n","#     rf_params.update(model_params)\n","#     model = RandomForestRegressor(**rf_params)\n","\n","#     print(\"  Preprocessing \u0026 Fitting RandomForestRegressor...\")\n","#     X_tr_trans = pipeline.fit_transform(X_tr, y_tr)\n","#     X_val_trans = pipeline.transform(X_val)\n","\n","#     start = time.time()\n","#     model.fit(X_tr_trans, y_tr)\n","#     train_time = time.time() - start\n","#     print(f\"  Training finished in {train_time:.1f}s\")\n","\n","#     del X_tr, X_val, X_tr_trans, X_val_trans, y_tr, y_val\n","#     gc.collect()\n","\n","#     # --- Save model first ---\n","#     results = {\n","#         \"description\": description,\n","#         \"training_time\": train_time,\n","#         \"parameters\": model.get_params(),\n","#     }\n","\n","#     if checkpoint_dir:\n","#         os.makedirs(checkpoint_dir, exist_ok=True)\n","#         safe_desc = \"\".join([c if c.isalnum() else \"_\" for c in description])\n","#         ts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n","\n","#         path = os.path.join(checkpoint_dir, f\"{safe_desc}_{ts}.joblib\")\n","#         print(f\"  Saving model to: {path} ...\")\n","#         joblib.dump(InferencePipeline(pipeline, model), path)\n","#         results[\"checkpoint_path\"] = path\n","\n","#     # 5. Evaluate\n","#     print(\"  Evaluating on Test set examples...\")\n","#     try:\n","#         X_test = pd.read_csv(X_test_path)\n","#         y_test = pd.read_csv(y_test_path)[REGR_TARGET].squeeze()\n","\n","#         if pos_only:\n","#             print(\"  pos_only is True, testing on only positive examples\")\n","#             mask_test_pos = (y_test \u003e 0)\n","#             X_test = X_test[mask_test_pos]\n","#             y_test = y_test[mask_test_pos]\n","#         else:\n","#             print(\"  pos_only is False, testing on WHOLE test set\")\n","\n","#         X_test_trans = pipeline.transform(X_test)\n","#         y_pred = model.predict(X_test_trans)\n","\n","#         y_pred_safe = np.maximum(y_pred, 1e-9)\n","\n","#         results.update({\n","#             \"rmse\": root_mean_squared_error(y_test, y_pred),\n","#             \"mae\": mean_absolute_error(y_test, y_pred),\n","#             \"mape\": mean_absolute_percentage_error(y_test, y_pred),\n","#             \"r2\": r2_score(y_test, y_pred),\n","#         })\n","\n","#         # Advanced metrics\n","#         try:\n","#             results[\"gamma_deviance\"] = mean_gamma_deviance(y_test, y_pred_safe)\n","#         except Exception as e:\n","#             print(f\"  Warning: Gamma deviance calc failed: {e}\")\n","\n","#         try:\n","#             results[\"tweedie_deviance\"] = mean_tweedie_deviance(\n","#                 y_test, y_pred_safe, power=1.5\n","#             )\n","#         except Exception as e:\n","#             print(f\"  Warning: Tweedie deviance calc failed: {e}\")\n","\n","#         # Extra custom metrics\n","#         if extra_metrics:\n","#             for name, func in extra_metrics.items():\n","#                 try:\n","#                     results[name] = func(y_test, y_pred)\n","#                 except Exception as e:\n","#                     print(f\"  Warning: Custom metric '{name}' failed: {e}\")\n","\n","#         print(f\"  RMSE:  {results.get('rmse', 'N/A'):.4f}\")\n","#         print(f\"  MAE:   {results.get('mae', 'N/A'):.4f}\")\n","#         print(f\"  MAPE:  {results.get('mape', 'N/A'):.4%}\")\n","\n","#         # Save Metrics JSON\n","#         if checkpoint_dir and \"checkpoint_path\" in results:\n","#             json_path = results[\"checkpoint_path\"].replace(\".joblib\", \"_metrics.json\")\n","#             with open(json_path, \"w\") as f:\n","#                 json.dump(results, f, indent=4)\n","#             print(f\"  Metrics saved to: {json_path}\")\n","\n","#     except Exception as e:\n","#         print(\"\\n!!! CRITICAL WARNING: Evaluation crashed, but Model IS SAVED !!!\")\n","#         print(f\"Error details: {e}\")\n","\n","#     return results\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":110660,"status":"ok","timestamp":1764867462141,"user":{"displayName":"Man-Ching Fung","userId":"01597576862106041674"},"user_tz":300},"id":"-1GmysFZSX9z","outputId":"3abcb293-f7de-4049-c387-e00b93ca7786"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","--- Starting Regressor Training: RF_Reg_pos_only ---\n","  Loading Training Data...\n","  Filtering for positive delays... (Original: 5086383)\n","  Training samples remaining: 877028\n","  Creating Validation Split (15%)...\n","  Preprocessing \u0026 Fitting RandomForestRegressor...\n","[cuml.accel] `RandomForestRegressor.fit` ran on GPU\n","  Training finished in 35.8s\n","  Saving model to: /content/drive/My Drive/CIS 5200 Final Project/models/random_forests/RF_Reg_pos_only_20251204_165715.joblib ...\n","[cuml.accel] `RandomForestRegressor` fitted attributes synced to CPU\n","  Evaluating on Test set examples...\n","  pos_only is True, testing on only positive examples\n","[cuml.accel] `RandomForestRegressor.predict` ran on GPU\n","  RMSE:  22.0088\n","  MAE:   17.5426\n","  MAPE:  238.2439%\n","  Metrics saved to: /content/drive/My Drive/CIS 5200 Final Project/models/random_forests/RF_Reg_pos_only_20251204_165715_metrics.json\n"]}],"source":["results_reg = train_regressor(\n","    X_train_path,\n","    y_train_path,\n","    X_test_path,\n","    y_test_path,\n","    description=\"RF_Reg_pos_only\",\n","    pos_only=True,\n","    checkpoint_dir=checkpoint_dir\n",")"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}